{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty lists to store athlete, sponsor, school, sport names, and values\n",
    "athlete_names = []\n",
    "sponsor_names = []\n",
    "school_names = []\n",
    "sport_names = []\n",
    "values = []\n",
    "instagram_links = []\n",
    "twitter_links = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the first 10 pages of the website and scrape athlete, sponsor, school, sport, and details link names.\n",
    "# Range may be changed to scrape additional pages, up to 541.\n",
    "for i in range(1, 11):\n",
    "    url = f\"https://nilcollegeathletes.com/deals?page={i}\"\n",
    "    html = requests.get(url)\n",
    "    soup = BeautifulSoup(html.content, 'html.parser')\n",
    "\n",
    "    # Find all the li tags with similar scraped data\n",
    "    li_tags = soup.find_all('li', {'class': 'relative pl-0 pr-6 py-5 hover:bg-gray-50 sm:py-6'})\n",
    "\n",
    "    # Loop through the <li> tags to find athlete, sponsor, school, sport, and details link names\n",
    "    for li in li_tags:\n",
    "        find_athlete = li.find('a', href=re.compile('/athletes/([\\w-]+)'))\n",
    "        find_sponsor = li.find('a', href=re.compile('/sponsors/|/agencies/'))\n",
    "        find_school = li.find('a', href=re.compile('/universities/'))\n",
    "        find_sport = li.find('div', {'class': 'flex text-gray-500 text-sm space-x-2'})\n",
    "        find_details = li.find('a', {'class': 'relative text-sm text-gray-500 hover:text-gray-900 font-medium'})\n",
    "\n",
    "        if find_athlete is not None:\n",
    "            athlete_url = 'https://nilcollegeathletes.com' + find_athlete['href']\n",
    "            athlete_html = requests.get(athlete_url)\n",
    "            athlete_soup = BeautifulSoup(athlete_html.content, 'html.parser')\n",
    "            instagram_link = athlete_soup.find('a', href=re.compile('instagram.com/'))\n",
    "            instagram_link = instagram_link.get('href') if instagram_link is not None else 'None'\n",
    "            twitter_link = athlete_soup.find('a', href=re.compile('twitter.com/'))\n",
    "            twitter_link = twitter_link.get('href') if twitter_link is not None else 'None'\n",
    "        else:\n",
    "            instagram_link = 'None'\n",
    "            twitter_link = 'None'\n",
    "\n",
    "        if find_sponsor is not None:\n",
    "            sponsor_name = find_sponsor.text.strip()\n",
    "        else:\n",
    "            sponsor_name = 'None'\n",
    "\n",
    "        if find_school is not None:\n",
    "            school_name = re.findall(r'/universities/([^\"]+)', str(find_school))[0]\n",
    "            school_name = school_name.replace('-', ' ') # Replace the - symbols with spaces\n",
    "        else:\n",
    "            school_name = 'None'\n",
    "\n",
    "        if find_sport is not None:\n",
    "            sport_name = find_sport.find_all('span')[-1].text.strip()\n",
    "        else:\n",
    "            sport_name = 'None'\n",
    "\n",
    "        value = np.nan  # Define value outside of the conditional block\n",
    "\n",
    "        if find_details is not None:\n",
    "            details = 'https://nilcollegeathletes.com' + find_details['href']\n",
    "            # Follow the link in details and scrape the value\n",
    "            html = requests.get(details)\n",
    "            soup = BeautifulSoup(html.content, 'html.parser')\n",
    "            value_tag = soup.find('dt', string='Value')\n",
    "            if value_tag is not None:\n",
    "                value = value_tag.find_next_sibling('dd').text.strip()\n",
    "                value = re.findall(r'\\$?\\d[\\d,.]*', value)\n",
    "                value = value[0].replace(',', '').replace('$', '') if len(value) > 0 else 'NaN'\n",
    "        else:\n",
    "            value = 'NaN'\n",
    "\n",
    "        athlete_names.append(find_athlete.text.strip())\n",
    "        sponsor_names.append(sponsor_name)\n",
    "        school_names.append(school_name)\n",
    "        sport_names.append(sport_name)\n",
    "        values.append(value)\n",
    "        instagram_links.append(instagram_link)\n",
    "        twitter_links.append(twitter_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with athlete, sponsor, school, sport names, and values\n",
    "nil = pd.DataFrame({'Athlete Name': athlete_names, 'Sponsor Name': sponsor_names, 'School': school_names, 'Sport': sport_names, 'Value': values, 'Instagram page': instagram_links, 'Twitter page': twitter_links})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sponsor_mode = nil['Sponsor Name'].mode()[0]\n",
    "print(f\"The most common occurring sponsor is: {sponsor_mode}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_value = nil['Value'].loc[nil['Value'] != 'NaN'].astype(float).mean()\n",
    "print(\"Mean Value:\", mean_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to search the dataFrame by athlete name\n",
    "athlete_search = input(\"Enter athlete name: \")\n",
    "athlete_data = nil[nil['Athlete Name'].str.contains(athlete_search, case=False)]\n",
    "print(athlete_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to serach the dataFrame by school\n",
    "school_search = input(\"Enter school name: \")\n",
    "school_data = nil[nil['School'].str.contains(school_search, case=False)]\n",
    "print(school_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to search the dataFrame by sponsor\n",
    "sponsor_search = input(\"Enter sponsor name: \")\n",
    "sponsor_data = nil[nil['Sponsor Name'].str.contains(sponsor_search, case=False)]\n",
    "print(sponsor_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to search the dataFrame by sport\n",
    "sport_search = input(\"Enter sport name: \")\n",
    "sport_data = nil[nil['Sport'].str.contains(sport_search, case=False)]\n",
    "print(sport_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by sport and count the number of occurrences\n",
    "sport_count = nil.groupby('Sport').size().reset_index(name='Counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.pie(sport_count, values='Counts', names='Sport', title='NIL Deals by Sport')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-data",
   "language": "python",
   "name": "python-data"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
